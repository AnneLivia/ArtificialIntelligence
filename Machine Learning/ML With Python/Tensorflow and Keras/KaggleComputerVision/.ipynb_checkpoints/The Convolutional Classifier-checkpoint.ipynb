{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2056be97",
   "metadata": {},
   "source": [
    "## Computer Vision!\n",
    "\n",
    "In this course, you'll:\n",
    "\n",
    "- Use modern deep-learning networks to build an image classifier with Keras\n",
    "- Design your own custom convnet with reusable blocks\n",
    "- Learn the fundamental ideas behind visual feature extraction\n",
    "- Master the art of transfer learning to boost your models\n",
    "- Utilize data augmentation to extend your dataset\n",
    "- If you've taken the Introduction to Deep Learning course, you'll know everything you need to be successful.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This course will introduce you to the fundamental ideas of computer vision. Our goal is to learn how a neural network can \"understand\" a natural image well-enough to solve the same kinds of problems the human visual system can solve.\n",
    "\n",
    "The neural networks that are best at this task are called convolutional neural networks (Sometimes we say convnet or CNN instead.) Convolution is the mathematical operation that gives the layers of a convnet their unique structure. In future lessons, you'll learn why this structure is so effective at solving computer vision problems.\n",
    "\n",
    "We will apply these ideas to the problem of image classification: given a picture, can we train a computer to tell us what it's a picture of? You may have seen apps that can identify a species of plant from a photograph. That's an image classifier! In this course, you'll learn how to build image classifiers just as powerful as those used in professional applications.\n",
    "\n",
    "While our focus will be on image classification, what you'll learn in this course is relevant to every kind of computer vision problem. At the end, you'll be ready to move on to more advanced applications like generative adversarial networks and image segmentation.\n",
    "\n",
    "## The Convolutional Classifier\n",
    "\n",
    "A convnet used for image classification consists of two parts: a convolutional base and a dense head.\n",
    "\n",
    "<img src=\"https://i.imgur.com/U0n5xjU.png\"/>\n",
    "\n",
    "The **base** is used to **extract the features from an image**. **It is formed primarily of layers performing the convolution operation**, but often includes other kinds of layers as well. (You'll learn about these in the next lesson.)\n",
    "\n",
    "The **head** is used to **determine the class of the image**. It is formed primarily of **dense layers, but might include other layers like dropout**.\n",
    "\n",
    "What do we mean by visual feature? A feature could be a line, a color, a texture, a shape, a pattern -- or some complicated combination.\n",
    "\n",
    "The whole process goes something like this:\n",
    "\n",
    "<img src=\"https://i.imgur.com/UUAafkn.png\" width=50%/>\n",
    "\n",
    "The features actually extracted look a bit different, but it gives the idea.\n",
    "\n",
    "## Training the Classifier\n",
    "\n",
    "The goal of the network during training is to learn two things:\n",
    "\n",
    "1. which features to extract from an image (base),\n",
    "2. which class goes with what features (head).\n",
    "\n",
    "These days, convnets are rarely trained from scratch. More often, we **reuse the base of a pretrained model**. To the pretrained base we then **attach an untrained head**. In other words, we reuse the part of a network that has already learned to do 1. Extract features, and attach to it some fresh layers to learn 2. Classify.\n",
    "\n",
    "<img src=\"https://imgur.com/E49fsmV.png\" width=50%/>\n",
    "\n",
    "Because the head usually consists of only a few dense layers, very accurate classifiers can be created from relatively little data.\n",
    "\n",
    "Reusing a **pretrained model** is a technique known as transfer learning. It is so effective, that almost every image classifier these days will make use of it.\n",
    "\n",
    "## Example - Train a Convnet Classifier\n",
    "\n",
    "Throughout this course, we're going to be creating classifiers that attempt to solve the following problem: is this a picture of a Car or of a Truck? Our dataset is about 10,000 pictures of various automobiles, around half cars and half trucks.\n",
    "\n",
    "## Step 1 - Load Data\n",
    "\n",
    "This next hidden cell will import some libraries and set up our data pipeline. We have a training split called ds_train and a validation split called ds_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fce72",
   "metadata": {},
   "source": [
    "If your directory structure is:\n",
    "\n",
    "    main_directory/\n",
    "    ...class_a/\n",
    "    ......a_image_1.jpg\n",
    "    ......a_image_2.jpg\n",
    "    ...class_b/\n",
    "    ......b_image_1.jpg\n",
    "    ......b_image_2.jpg\n",
    "\n",
    "Then calling **image_dataset_from_directory**(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\n",
    "\n",
    "**Supported image formats: jpeg, png, bmp, gif. Animated gifs are truncated to the first frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb22409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec # A grid layout to place subplots within a figure\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Generates a tf.data.Dataset from image files in a directory.\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798ab48",
   "metadata": {},
   "source": [
    "Neural network algorithms are stochastic.\n",
    "\n",
    "This means they make use of randomness, such as initializing to random weights, and in turn the same network trained on the same data can produce different results.\n",
    "\n",
    "This can be confusing to beginners as the algorithm appears unstable, and in fact they are by design. The random initialization allows the network to learn a good approximation for the function being learned.\n",
    "\n",
    "Nevertheless, there are times when you need the exact same result every time the same network is trained on the same data\n",
    "\n",
    "Link: https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "\n",
    "When you are training or running a tensorflow model, you may find a confused phenomena: The model result may have a little difference during multiple executions, which means the tensorflow model result is not stable. You can not get repeated result.\n",
    "\n",
    "Why tensorflow model result is not stable?\n",
    "\n",
    "The main reason is the weight variables are initialized by some random initializers in tensorflow. These random initializers will generate different values for weight variables in tensorflow.\n",
    "\n",
    "How to make tensorflow model result is stable?\n",
    "\n",
    "We should make random initializers generate the same values during different executions. We can set a random seed.\n",
    "\n",
    "Bellow, it was set a SEED for python, numpy and tensorflow random initializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259442ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(31415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a44490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42a136",
   "metadata": {},
   "source": [
    "interpolation: String, the interpolation method used when resizing images.\n",
    "    Defaults to `bilinear`. Supports `bilinear`, `nearest`, `bicubic`,\n",
    "    `area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fa75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    'data/car-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab6a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5051 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_valid_ = image_dataset_from_directory(\n",
    "    'data/car-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c896c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798d7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0ed01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27459672",
   "metadata": {},
   "source": [
    "Let's take a look at a few examples from the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9226dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bbc43",
   "metadata": {},
   "source": [
    "## Step 2 - Define Pretrained Base\n",
    "\n",
    "The most commonly used dataset for pretraining is ImageNet, a large dataset of many kind of natural images. Keras includes a variety models pretrained on ImageNet in its applications module. The pretrained model we'll use is called VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4adbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "pretrained_base = tf.keras.models.load_model(\n",
    "    'data/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe2433",
   "metadata": {},
   "source": [
    "## Step 3 - Attach Head\n",
    "\n",
    "Next, we attach the classifier head. For this example, we'll use a layer of hidden units (the first Dense layer) followed by a layer to transform the outputs to a probability score for class 1, Truck. The Flatten layer transforms the two dimensional outputs of the base into the one dimensional inputs needed by the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e9ddf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f9765",
   "metadata": {},
   "source": [
    "## Step 4 - Train\n",
    "\n",
    "Finally, let's train the model. Since this is a two-class problem, we'll use the binary versions of crossentropy and accuracy. The adam optimizer generally performs well, so we'll choose it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ec42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f61994",
   "metadata": {},
   "source": [
    "When training a neural network, it's always a good idea to examine the loss and metric plots. The history object contains this information in a dictionary history.history. We can use Pandas to convert this dictionary to a dataframe and plot it with a built-in method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363923d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a390d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lesson, we learned about the structure of a convnet classifier: a head to act as a classifier atop of a base which performs the feature extraction.\n",
    "\n",
    "The head, essentially, is an ordinary classifier like you learned about in the introductory course. For features, it uses those features extracted by the base. This is the basic idea behind convolutional classifiers: that we can attach a unit that performs feature engineering to the classifier itself.\n",
    "\n",
    "This is one of the big advantages deep neural networks have over traditional machine learning models: given the right network structure, the deep neural net can learn how to engineer the features it needs to solve its problem.\n",
    "\n",
    "For the next few lessons, we'll take a look at how the convolutional base accomplishes the feature extraction. Then, you'll learn how to apply these ideas and design some classifiers of your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b5691",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd95e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
