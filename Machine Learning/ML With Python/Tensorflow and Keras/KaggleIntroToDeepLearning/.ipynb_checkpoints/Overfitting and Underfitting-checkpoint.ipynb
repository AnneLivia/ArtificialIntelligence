{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a432cc1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Recall from the example in the previous lesson that Keras will keep a history of the training and validation loss over the epochs that it is training the model. In this lesson, we're going to learn how to interpret these learning curves and how we can use them to guide model development. In particular, we'll examine at the learning curves for evidence of underfitting and overfitting and look at a couple of strategies for correcting it.\n",
    "\n",
    "# Interpreting the Learning Curves\n",
    "\n",
    "You might think about the information in the training data as being of two kinds: **signal and noise**. The **signal** is the part that generalizes, the part that can help our model make predictions from new data. The **noise** is that **part that is only true of the training data**; the noise is all of the random fluctuation that comes from data in the real-world or all of the incidental, non-informative patterns that can't actually help the model make predictions. The noise is the part might look useful but really isn't.\n",
    "\n",
    "We train a model by choosing weights or parameters that minimize the loss on a training set. You might know, however, that to accurately assess a model's performance, we need to evaluate it on a new set of data, the validation data. (You could see our lesson on model validation in Introduction to Machine Learning for a review.)\n",
    "\n",
    "When we train a model we've been plotting the loss on the training set epoch by epoch. To this we'll add a plot the validation data too. These plots we call the learning curves. To train deep learning models effectively, we need to be able to interpret them.\n",
    "\n",
    "<img src=\"https://i.imgur.com/tHiVFnM.png\"/>\n",
    "\n",
    "**The validation loss gives an estimate of the expected error on unseen data.**\n",
    "\n",
    "Now, the training loss will go down either when the model learns signal or when it learns noise. **But the validation loss will go down only when the model learns signal**. (Whatever noise the model learned from the training set won't generalize to new data.) So, when a model learns signal both curves go down, ***but when it learns noise a gap is created in the curves*. The size of the gap tells you how much noise the model has learned**.\n",
    "\n",
    "Ideally, we would create models that learn all of the signal and none of the noise. This will practically never happen. Instead we make a trade. We can get the model to learn more signal at the cost of learning more noise. So long as the trade is in our favor, the validation loss will continue to decrease. After a certain point, however, the trade can turn against us, the cost exceeds the benefit, and the validation loss begins to rise.\n",
    "\n",
    "<img src=\"https://i.imgur.com/eUF6mfo.png\"/>\n",
    "\n",
    "This trade-off indicates that there can be two problems that occur when training a model: not enough signal or too much noise. **Underfitting the training set is when the loss is not as low as it could be because the model hasn't learned enough signal**. **Overfitting the training set is when the loss is not as low as it could be because the model learned too much noise**. The trick to training deep learning models is finding **the best balance between the two**.\n",
    "\n",
    "We'll look at a couple ways of getting more signal out of the training data while reducing the amount of noise.\n",
    "\n",
    "# Capacity\n",
    "\n",
    "**A model's *capacity* refers to the size and complexity of the patterns it is able to learn.**\n",
    "\n",
    "For neural networks, this will largely be **determined by how many neurons it has and how they are connected together**. If it appears that your network is underfitting the data, you should try increasing its capacity.\n",
    "\n",
    "You can increase the capacity of a network either by making it wider (more units to existing layers) or by making it deeper (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset.\n",
    "\n",
    "'''\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    wider = keras.Sequential([\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    deeper = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "'''\n",
    "\n",
    "You'll explore how the capacity of a network can affect its performance in the exercise.\n",
    "\n",
    "# Early Stopping\n",
    "\n",
    "We mentioned that when a model is too eagerly learning noise, the validation loss may start to increase during training. To prevent this, **we can simply stop the training whenever it seems the validation loss isn't decreasing anymore**. Interrupting the training this way is called **early stopping**.\n",
    "\n",
    "<img src=\"https://i.imgur.com/eP0gppr.png\"/>\n",
    "\n",
    "*We keep the model where the validation loss is at a minimum.*\n",
    "\n",
    "Once we detect that the validation loss is starting to rise again, we can reset the weights back to where the minimum occured. This ensures that the model won't continue to learn noise and overfit the data.\n",
    "\n",
    "Training with early stopping also means we're in less danger of stopping the training too early, before the network has finished learning signal. **So besides preventing overfitting from training too long, early stopping can also prevent underfitting from not training long enough**. Just set your training epochs to some large number (more than you'll need), and early stopping will take care of the rest.\n",
    "\n",
    "# Adding Early Stopping\n",
    "\n",
    "In Keras, we include early stopping in our training through a callback. A callback is just a function you want run every so often while the network trains. The early stopping callback will run after every epoch. (Keras has a variety of useful callbacks pre-defined, but you can define your own, too.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da8aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping # Stop training when a monitored metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ce3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4748b",
   "metadata": {},
   "source": [
    "These parameters say: \"If there hasn't been at least an improvement of 0.001 in the validation loss over the previous 20 epochs, then stop the training and keep the best model you found.\" It can sometimes be hard to tell if the validation loss is rising due to overfitting or just due to random batch variation. **The parameters allow us to set some allowances around when to stop**.\n",
    "\n",
    "As we'll see in our example, we'll pass this callback to the fit method along with the loss and optimizer.\n",
    "\n",
    "# Example - Train a Model with Early Stopping\n",
    "\n",
    "Let's continue developing the model from the example in the last tutorial. We'll increase the capacity of that network but also add an early-stopping callback to prevent overfitting.\n",
    "\n",
    "Here's the data prep again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6deb2f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "red_wine = pd.read_csv('data/red-wine.csv')\n",
    "\n",
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da6a0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and validation splits (70% train)\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
    "df_valid = red_wine.drop(df_train.index) # removing the rows that was selected to insert in the df_train\n",
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121131d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to [0, 1] all of the collunms\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1509391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X_train = df_train.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd783f",
   "metadata": {},
   "source": [
    "Now let's increase the capacity of the network. We'll go for a fairly large network, but rely on the callback to halt the training once the validation loss shows signs of increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf86386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5aaabb",
   "metadata": {},
   "source": [
    "patience: Number of epochs with no improvement\n",
    "      after which training will be stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be90a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the callback for early stopping\n",
    "early_stop = callbacks.EarlyStopping (min_delta=0.001, patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98078206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bcb5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01813857",
   "metadata": {},
   "source": [
    "After defining the callback, add it as an argument in fit (you can have several, so put it in a list). Choose a large number of epochs when using early stopping, more than you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8462bd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 4s 99ms/step - loss: 0.2966 - val_loss: 0.1427\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1406 - val_loss: 0.1301\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1273 - val_loss: 0.1182\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1170 - val_loss: 0.1101\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1109 - val_loss: 0.1068\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1086 - val_loss: 0.1022\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1043 - val_loss: 0.1043\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1036 - val_loss: 0.1032\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1028 - val_loss: 0.1003\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1010 - val_loss: 0.1014\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1009 - val_loss: 0.0987\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0993 - val_loss: 0.0985\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0973 - val_loss: 0.1030\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0960 - val_loss: 0.0975\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0966 - val_loss: 0.0964\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0973 - val_loss: 0.1005\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1000 - val_loss: 0.1041\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0953 - val_loss: 0.1098\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0982 - val_loss: 0.0985\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0948 - val_loss: 0.0975\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0934 - val_loss: 0.0964\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0914 - val_loss: 0.0985\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0915 - val_loss: 0.1034\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0940 - val_loss: 0.1001\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0912 - val_loss: 0.0998\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0902 - val_loss: 0.0956\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0889 - val_loss: 0.0956\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0898 - val_loss: 0.0954\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0899 - val_loss: 0.0946\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0893 - val_loss: 0.0958\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0918 - val_loss: 0.1091\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0932 - val_loss: 0.1064\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0922 - val_loss: 0.0950\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0880 - val_loss: 0.0935\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0879 - val_loss: 0.0950\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0856 - val_loss: 0.0940\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0847 - val_loss: 0.0948\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0843 - val_loss: 0.0946\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0834 - val_loss: 0.0951\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0845 - val_loss: 0.0936\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0857 - val_loss: 0.0940\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0821 - val_loss: 0.0940\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0834 - val_loss: 0.0949\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0827 - val_loss: 0.0938\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0824 - val_loss: 0.0940\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0824 - val_loss: 0.0974\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0829 - val_loss: 0.0952\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0815 - val_loss: 0.1042\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0863 - val_loss: 0.0950\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0813 - val_loss: 0.0969\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0801 - val_loss: 0.0918\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0791 - val_loss: 0.0933\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0816 - val_loss: 0.0915\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0777 - val_loss: 0.0921\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0774 - val_loss: 0.0969\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0786 - val_loss: 0.0930\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0779 - val_loss: 0.0969\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0798 - val_loss: 0.0940\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0845 - val_loss: 0.1007\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0881 - val_loss: 0.1031\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0911 - val_loss: 0.0938\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0825 - val_loss: 0.0977\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0797 - val_loss: 0.0941\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0770 - val_loss: 0.0934\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0773 - val_loss: 0.0964\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0760 - val_loss: 0.0931\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0755 - val_loss: 0.0959\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0765 - val_loss: 0.0925\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0759 - val_loss: 0.0918\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0766 - val_loss: 0.0915\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0747 - val_loss: 0.0921\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size = 256, \n",
    "    epochs=500, \n",
    "    callbacks=[early_stop], \n",
    "    verbose=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bff04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef050c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.296605</td>\n",
       "      <td>0.142727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140557</td>\n",
       "      <td>0.130101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127261</td>\n",
       "      <td>0.118222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116952</td>\n",
       "      <td>0.110142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110940</td>\n",
       "      <td>0.106812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.296605  0.142727\n",
       "1  0.140557  0.130101\n",
       "2  0.127261  0.118222\n",
       "3  0.116952  0.110142\n",
       "4  0.110940  0.106812"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deac7bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.loc[:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d96b30b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 0.09146713465452194\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de462f2f",
   "metadata": {},
   "source": [
    "And sure enough, Keras stopped the training well before the full 500 epochs!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91692be0",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66649451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99419be0",
   "metadata": {},
   "source": [
    "First load the Spotify dataset. Your task will be to predict the **popularity** of a song based on various audio features, like 'tempo', 'danceability', and 'mode'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd51251",
   "metadata": {},
   "source": [
    "StandardScaler = Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standard score of a sample x is calculated as: z = (x - u) / s. Z-score\n",
    "\n",
    "Many machine learning algorithms perform better when numerical input variables are scaled to a standard range.\n",
    "\n",
    "This includes algorithms that use a weighted sum of the input, like linear regression, and algorithms that use distance measures, like k-nearest neighbors. The two most popular techniques for scaling numerical data prior to modeling are normalization and standardization. Normalization scales each input variable separately to the range 0-1, which is the range for floating-point values where we have the most precision. Standardization scales each input variable separately by subtracting the mean (called centering) and dividing by the standard deviation to shift the distribution to have a mean of zero and a standard deviation of one. More information here: https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3442db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc70c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "732e1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = pd.read_csv('data/spotify.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d1c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
       "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>66</td>\n",
       "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
       "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.518</td>\n",
       "      <td>122.036</td>\n",
       "      <td>194754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
       "      <td>Memories - Dillon Francis Remix</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>67</td>\n",
       "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
       "      <td>Memories (Dillon Francis Remix)</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.693</td>\n",
       "      <td>99.972</td>\n",
       "      <td>162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1z1Hg7Vb0AhHDiEmnDE79l</td>\n",
       "      <td>All the Time - Don Diablo Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>70</td>\n",
       "      <td>1HoSmj2eLcsrR0vE9gThr4</td>\n",
       "      <td>All the Time (Don Diablo Remix)</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.613</td>\n",
       "      <td>124.008</td>\n",
       "      <td>176616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75FpbthrwQmzHlBJLuGdC7</td>\n",
       "      <td>Call You Mine - Keanu Silva Remix</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>60</td>\n",
       "      <td>1nqYsOef1yKKuGOVchbsk6</td>\n",
       "      <td>Call You Mine - The Remixes</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.277</td>\n",
       "      <td>121.956</td>\n",
       "      <td>169093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e8PAfcKUYoKkxPhrHqw4x</td>\n",
       "      <td>Someone You Loved - Future Humans Remix</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>69</td>\n",
       "      <td>7m7vv9wlQ4i0LFuJiE2zsQ</td>\n",
       "      <td>Someone You Loved (Future Humans Remix)</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.725</td>\n",
       "      <td>123.976</td>\n",
       "      <td>189052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                         track_name  \\\n",
       "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
       "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
       "2  1z1Hg7Vb0AhHDiEmnDE79l                    All the Time - Don Diablo Remix   \n",
       "3  75FpbthrwQmzHlBJLuGdC7                  Call You Mine - Keanu Silva Remix   \n",
       "4  1e8PAfcKUYoKkxPhrHqw4x            Someone You Loved - Future Humans Remix   \n",
       "\n",
       "       track_artist  track_popularity          track_album_id  \\\n",
       "0        Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
       "1          Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
       "2      Zara Larsson                70  1HoSmj2eLcsrR0vE9gThr4   \n",
       "3  The Chainsmokers                60  1nqYsOef1yKKuGOVchbsk6   \n",
       "4     Lewis Capaldi                69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
       "\n",
       "                                    track_album_name track_album_release_date  \\\n",
       "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
       "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
       "2                    All the Time (Don Diablo Remix)               2019-07-05   \n",
       "3                        Call You Mine - The Remixes               2019-07-19   \n",
       "4            Someone You Loved (Future Humans Remix)               2019-03-05   \n",
       "\n",
       "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
       "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   6    -2.634   \n",
       "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...  11    -4.969   \n",
       "2     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -3.432   \n",
       "3     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   7    -3.778   \n",
       "4     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -4.672   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     1       0.0583        0.1020          0.000000    0.0653    0.518   \n",
       "1     1       0.0373        0.0724          0.004210    0.3570    0.693   \n",
       "2     0       0.0742        0.0794          0.000023    0.1100    0.613   \n",
       "3     1       0.1020        0.0287          0.000009    0.2040    0.277   \n",
       "4     1       0.0359        0.0803          0.000000    0.0833    0.725   \n",
       "\n",
       "     tempo  duration_ms  \n",
       "0  122.036       194754  \n",
       "1   99.972       162600  \n",
       "2  124.008       176616  \n",
       "3  121.956       169093  \n",
       "4  123.976       189052  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "753bdb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32833 entries, 0 to 32832\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   track_id                  32833 non-null  object \n",
      " 1   track_name                32828 non-null  object \n",
      " 2   track_artist              32828 non-null  object \n",
      " 3   track_popularity          32833 non-null  int64  \n",
      " 4   track_album_id            32833 non-null  object \n",
      " 5   track_album_name          32828 non-null  object \n",
      " 6   track_album_release_date  32833 non-null  object \n",
      " 7   playlist_name             32833 non-null  object \n",
      " 8   playlist_id               32833 non-null  object \n",
      " 9   playlist_genre            32833 non-null  object \n",
      " 10  playlist_subgenre         32833 non-null  object \n",
      " 11  danceability              32833 non-null  float64\n",
      " 12  energy                    32833 non-null  float64\n",
      " 13  key                       32833 non-null  int64  \n",
      " 14  loudness                  32833 non-null  float64\n",
      " 15  mode                      32833 non-null  int64  \n",
      " 16  speechiness               32833 non-null  float64\n",
      " 17  acousticness              32833 non-null  float64\n",
      " 18  instrumentalness          32833 non-null  float64\n",
      " 19  liveness                  32833 non-null  float64\n",
      " 20  valence                   32833 non-null  float64\n",
      " 21  tempo                     32833 non-null  float64\n",
      " 22  duration_ms               32833 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(10)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "spotify.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "701f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's no null, but use this command anyway\n",
    "X = spotify.copy().dropna()\n",
    "y = X.pop('track_popularity') # remove target from X and also returns it to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82b98f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        66\n",
       "1        67\n",
       "2        70\n",
       "3        60\n",
       "4        69\n",
       "         ..\n",
       "32828    42\n",
       "32829    20\n",
       "32830    14\n",
       "32831    15\n",
       "32832    27\n",
       "Name: track_popularity, Length: 32828, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88db9bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32828 entries, 0 to 32832\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   track_id                  32828 non-null  object \n",
      " 1   track_name                32828 non-null  object \n",
      " 2   track_artist              32828 non-null  object \n",
      " 3   track_album_id            32828 non-null  object \n",
      " 4   track_album_name          32828 non-null  object \n",
      " 5   track_album_release_date  32828 non-null  object \n",
      " 6   playlist_name             32828 non-null  object \n",
      " 7   playlist_id               32828 non-null  object \n",
      " 8   playlist_genre            32828 non-null  object \n",
      " 9   playlist_subgenre         32828 non-null  object \n",
      " 10  danceability              32828 non-null  float64\n",
      " 11  energy                    32828 non-null  float64\n",
      " 12  key                       32828 non-null  int64  \n",
      " 13  loudness                  32828 non-null  float64\n",
      " 14  mode                      32828 non-null  int64  \n",
      " 15  speechiness               32828 non-null  float64\n",
      " 16  acousticness              32828 non-null  float64\n",
      " 17  instrumentalness          32828 non-null  float64\n",
      " 18  liveness                  32828 non-null  float64\n",
      " 19  valence                   32828 non-null  float64\n",
      " 20  tempo                     32828 non-null  float64\n",
      " 21  duration_ms               32828 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(10)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c6da545",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = X['track_artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4772748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num = ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                'speechiness', 'acousticness', 'instrumentalness',\n",
    "                'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "features_cat = ['playlist_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b12ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), features_num), # fazer o stardard scaler in the features num\n",
    "    (OneHotEncoder(), features_cat), # fazer o one hot encoder in categoricals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26251883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
