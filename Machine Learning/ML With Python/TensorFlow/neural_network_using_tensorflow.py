# -*- coding: utf-8 -*-
"""Neural Network using Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LLEl0v4eY9bekEtaLPFgMOxZKpFmBui-

TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.

Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result as fast as possible is key to doing good research.

There are several differences between these two frameworks. Keras is a neural network library while TensorFlow is the open-source library for a number of various tasks in machine learning. TensorFlow provides both high-level and low-level APIs while Keras provides only high-level APIs. In terms of flexibility, Tensorflowâ€™s eager execution allows for immediate iteration along with intuitive debugging. Keras offers simple and consistent high-level APIs and follows best practices to reduce the cognitive load for the users. Both frameworks thus provide high-level APIs for building and training models with ease. Keras is built in Python which makes it way more user-friendly than TensorFlow. (https://analyticsindiamag.com/tensorflow-vs-keras-which-one-should-you-choose/)
"""

import tensorflow as tf

"""matplotlib.pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc."""

import matplotlib.pyplot as plt

"""Module: tf.keras.datasets:

boston_housing module: Boston housing price regression dataset.

cifar10 module: CIFAR10 small images classification dataset.

cifar100 module: CIFAR100 small images classification dataset.

fashion_mnist module: Fashion-MNIST dataset.

imdb module: IMDB sentiment classification dataset.

mnist module: MNIST handwritten digits dataset.

reuters module: Reuters topic classification dataset.
"""

mnist = tf.keras.datasets.mnist # dataset of handwritten digits from 0 to 9

(x_train, y_train), (x_test, y_test) = mnist.load_data(); # loading data from the dataset

# normalizing the data (makes easier for a network to learn)
x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

plt.imshow(x_train[0], cmap = plt.cm.binary)
plt.show()
# print(x_train[0])

# it's a black and white image (binary image)

"""A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.

A Sequential model is not appropriate when:

Your model has multiple inputs or multiple outputs
Any of your layers has multiple inputs or multiple outputs
You need to do layer sharing
You want non-linear topology (e.g. a residual connection, a multi-branch model)

There are three ways to create Keras models:

*   The Sequential model, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).
*   The Functional API, which is an easy-to-use, fully-featured API that supports arbitrary model architectures. For most people and most use cases, this is what you should be using. This is the Keras "industry strength" model.

*   Model subclassing, where you implement everything from scratch on your own. Use this if you have complex, out-of-the-box research use cases.


"""

# building the model to traning the neural network.
model = tf.keras.models.Sequential()
# the first layer is the input layer
# the array is 28 by 28 bidimensional array, we must flat that
model.add(tf.keras.layers.Flatten()) # input layer
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # 128 neurons and relu activation function (hidden layer)
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # 128 neurons and relu activation function (hidden layer)
model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) # 128 neurons and relu activation function (output layer)

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# train the model

model.fit(x_train, y_train, epochs=5)

"""The idea is that the model generalize and not overfitting, so calculate val_loss and val_acc"""

val_loss, val_acc = model.evaluate(x_test, y_test)
print(val_loss, val_acc)

"""Para salvar e carregar o modelo, usar os seguintes comandos:


"""

model.save('model_saved')
modelnew = tf.keras.models.load_model('model_saved')

predictions = modelnew.predict([x_test]);
print(predictions)

import numpy as np
print(np.argmax(predictions[0]))

plt.imshow(x_test[0])
plt.show()