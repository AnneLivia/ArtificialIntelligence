{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb11eeaf",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "In the first two lessons, we learned how to build fully-connected networks out of stacks of dense layers. When first created, all of the network's weights are set randomly -- the network doesn't \"know\" anything yet. In this lesson we're going to see how to train a neural network; we're going to see how neural networks learn.\n",
    "\n",
    "As with all machine learning tasks, we begin with a set of training data. Each example in the training data consists of some features (the inputs) together with an expected target (the output). Training the network means adjusting its weights in such a way that it can transform the features into the target. In the 80 Cereals dataset, for instance, we want a network that can take each cereal's 'sugar', 'fiber', and 'protein' content and produce a prediction for that cereal's 'calories'. If we can successfully train a network to do that, its weights must represent in some way the relationship between those features and that target as expressed in the training data.\n",
    "\n",
    "In addition to the training data, we need two more things:\n",
    "\n",
    "- A \"loss function\" that measures how good the network's predictions are.\n",
    "- An \"optimizer\" that can tell the network how to change its weights.\n",
    "\n",
    "# The Loss Function\n",
    "\n",
    "We've seen how to design an architecture for a network, but we haven't seen how to tell a network what problem to solve. This is the job of the loss function.\n",
    "\n",
    "The loss function measures the disparity between the the target's true value and the value the model predicts.\n",
    "\n",
    "Different problems call for different loss functions. We have been looking at regression problems, where the task is to predict some numerical value -- calories in 80 Cereals, rating in Red Wine Quality. Other regression tasks might be predicting the price of a house or the fuel efficiency of a car.\n",
    "\n",
    "A common loss function for regression problems is the mean absolute error or MAE. For each prediction y_pred, MAE measures the disparity from the true target y_true by an absolute difference abs(y_true - y_pred).\n",
    "\n",
    "The total MAE loss on a dataset is the mean of all these absolute differences.\n",
    "\n",
    "<img src=\"https://i.imgur.com/VDcvkZN.png\"/>\n",
    "*The mean absolute error is the average length between the fitted curve and the data points.*\n",
    "\n",
    "Besides MAE, other loss functions you might see for regression problems are the mean-squared error (MSE) or the Huber loss (both available in Keras).\n",
    "\n",
    "During training, the model will use the loss function as a guide for finding the correct values of its weights (lower loss is better). In other words, the loss function tells the network its objective.\n",
    "\n",
    "The Optimizer - Stochastic Gradient Descent\n",
    "We've described the problem we want the network to solve, but now we need to say how to solve it. This is the job of the optimizer. The optimizer is an algorithm that adjusts the weights to minimize the loss.\n",
    "\n",
    "Virtually all of the optimization algorithms used in deep learning belong to a family called stochastic gradient descent. They are iterative algorithms that train a network in steps. One step of training goes like this:\n",
    "\n",
    "1. Sample some training data and run it through the network to make predictions.\n",
    "2. Measure the loss between the predictions and the true values.\n",
    "3. Finally, adjust the weights in a direction that makes the loss smaller.\n",
    "\n",
    "Then just do this over and over until the loss is as small as you like (or until it won't decrease any further.)\n",
    "\n",
    "<img src=\"https://i.imgur.com/rFI1tIk.gif\"/>\n",
    "\n",
    "*Training a neural network with Stochastic Gradient Descent.*\n",
    "\n",
    "Each iteration's sample of training data is called a **minibatch** (or often just **\"batch\"**), while a complete round of the training data is called an **epoch**. The number of **epochs** you train for is **how many times the network will see each training example**.\n",
    "\n",
    "The animation shows the linear model from Lesson 1 being trained with **SGD**. The **pale red dots** depict the entire training set (epoch), while the **solid red dots** are the **minibatches**. Every time SGD sees a new minibatch, it will shift the weights *(w the slope and b the y-intercept)* toward their correct values on that batch.\n",
    "\n",
    "Batch after batch, the line eventually converges to its best fit. You can see that the loss gets smaller as the weights get closer to their true values.\n",
    "\n",
    "# Learning Rate and Batch Size\n",
    "\n",
    "Notice that the line only makes a small shift in the direction of each batch (instead of moving all the way). The size of these shifts is determined by the **learning rate**. A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values.\n",
    "\n",
    "The **learning rate** and the **size of the minibatches** are the two parameters that have the largest effect on how the SGD training proceeds. Their interaction is often subtle and the right choice for these parameters isn't always obvious. (We'll explore these effects in the exercise.)\n",
    "\n",
    "Fortunately, for most work it won't be necessary to do an extensive hyperparameter search to get satisfactory results. **Adam** is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). **Adam is a great general-purpose optimizer**.\n",
    "\n",
    "*Search for Adam Algorithm later to learn more*\n",
    "\n",
    "# Adding the Loss and Optimizer\n",
    "\n",
    "After defining a model, you can add a loss function and optimizer with the model's compile method:\n",
    "\n",
    "``model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    ")``\n",
    "\n",
    "Notice that we are able to specify the loss and optimizer with just a string. You can also access these directly through the Keras API -- if you wanted to tune parameters, for instance -- but for us, the defaults will work fine.\n",
    "\n",
    "``What's In a Name?\n",
    "The gradient is a vector that tells us in what direction the weights need to go. More precisely, it tells us how to change the weights to make the loss change fastest. We call our process gradient descent because it uses the gradient to descend the loss curve towards a minimum. Stochastic means \"determined by chance.\" Our training is stochastic because the minibatches are random samples from the dataset. And that's why it's called SGD!``\n",
    "\n",
    "# Example - Red Wine Quality\n",
    "\n",
    "Now we know everything we need to start training deep learning models. So let's see it in action! We'll use the Red Wine Quality dataset.\n",
    "\n",
    "This dataset consists of physiochemical measurements from about 1600 Portuguese red wines. Also included is a quality rating for each wine from blind taste-tests. How well can we predict a wine's perceived quality from these measurements?\n",
    "\n",
    "We've put all of the data preparation into this next hidden cell. It's not essential to what follows so feel free to skip it. One thing you might note for now though is that we've rescaled each feature to lie in the interval  [0,1] . As we'll discuss more in Lesson 5, neural networks tend to perform best when their inputs are on a common scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e56672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf231511",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv('data/red-wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95290eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation splits\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0);\n",
    "df_valid = red_wine.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9423cf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb5f56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4d0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19a8ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity            15.9000\n",
       "volatile acidity          1.5800\n",
       "citric acid               0.7900\n",
       "residual sugar           13.9000\n",
       "chlorides                 0.6110\n",
       "free sulfur dioxide      72.0000\n",
       "total sulfur dioxide    289.0000\n",
       "density                   1.0032\n",
       "pH                        3.9000\n",
       "sulphates                 1.9800\n",
       "alcohol                  14.9000\n",
       "quality                   8.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ # getting the maximum of every colunm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215b1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "937e8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X_train = df_train.drop('quality', axis=1)\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1978d2",
   "metadata": {},
   "source": [
    "How many inputs should this network have? We can discover this by looking at the number of columns in the data matrix. Be sure not to include the target ('quality') here -- only the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad5797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751e09ff",
   "metadata": {},
   "source": [
    "Eleven columns means eleven inputs.\n",
    "\n",
    "We've chosen a three-layer network with over 1500 neurons. This network should be capable of learning fairly complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "189b7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4c5f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(units=512, input_shape=[X_train.shape[1]]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(512),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.Dense(units=1) # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ec31f",
   "metadata": {},
   "source": [
    "Deciding the architecture of your model should be part of a process. Start simple and use the validation loss as your guide. You'll learn more about model development in the exercises.\n",
    "\n",
    "After defining the model, we compile in the optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fda7dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f8d96",
   "metadata": {},
   "source": [
    "Now we're ready to start the training! We've told Keras to feed the optimizer 256 rows of the training data at a time (the batch_size) and to do that 10 times all the way through the dataset (the epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea81dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 4s 104ms/step - loss: 0.2584 - val_loss: 0.1321\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1440 - val_loss: 0.1234\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.131 - 0s 28ms/step - loss: 0.1300 - val_loss: 0.1165\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1203 - val_loss: 0.1083\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1110 - val_loss: 0.1051\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1079 - val_loss: 0.1017\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1053 - val_loss: 0.1035\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1030 - val_loss: 0.1017\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1015 - val_loss: 0.1044\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.1008 - val_loss: 0.1000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55d0af",
   "metadata": {},
   "source": [
    "You can see that Keras will keep you updated on the loss as the model trains.\n",
    "\n",
    "Often, a better way to view the loss though is to plot it. The fit method in fact keeps a record of the loss produced during training in a History object. We'll convert the data to a Pandas dataframe, which makes the plotting easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4e528d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a083b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.258367</td>\n",
       "      <td>0.132052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144027</td>\n",
       "      <td>0.123447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129962</td>\n",
       "      <td>0.116501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120256</td>\n",
       "      <td>0.108334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111019</td>\n",
       "      <td>0.105144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.258367  0.132052\n",
       "1  0.144027  0.123447\n",
       "2  0.129962  0.116501\n",
       "3  0.120256  0.108334\n",
       "4  0.111019  0.105144"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e4f1524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Pandas native plot method\n",
    "history_df['loss'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f26218",
   "metadata": {},
   "source": [
    "Notice how the loss levels off as the epochs go by. When the loss curve becomes horizontal like that, it means the model has learned all it can and there would be no reason continue for additional epochs.\n",
    "\n",
    "Additional informations: \n",
    "\n",
    "Stochastic gradient descent is an optimization algorithm often used in machine learning applications to find the model parameters that correspond to the best fit between predicted and actual outputs. It's an inexact but powerful technique. Stochastic gradient descent is widely used in machine learning applications. Combined with backpropagation, itâ€™s dominant in neural network training applications.\n",
    "\n",
    "Neural networks find weights and biases with gradient descent.\n",
    "\n",
    "The cost function, or loss function, is the function to be minimized (or maximized) by varying the decision variables. Many machine learning methods solve optimization problems under the surface. They tend to minimize the difference between actual and predicted outputs by adjusting the model parameters (like weights and biases for neural networks, decision rules for random forest or gradient boosting, and so on).\n",
    "\n",
    "Stochastic gradient descent algorithms are a modification of gradient descent. In stochastic gradient descent, you calculate the gradient using just a random small part of the observations instead of all of them. In some cases, this approach can reduce computation time.\n",
    "\n",
    "Online stochastic gradient descent is a variant of stochastic gradient descent in which you estimate the gradient of the cost function for each observation and update the decision variables accordingly. This can help you find the global minimum, especially if the objective function is convex.\n",
    "\n",
    "Batch stochastic gradient descent is somewhere between ordinary gradient descent and the online method. The gradients are calculated and the decision variables are updated iteratively with subsets of all observations, called minibatches. This variant is very popular for training neural networks.\n",
    "\n",
    "More information in <a href=\"https://realpython.com/gradient-descent-algorithm-python/#:~:text=Stochastic%20gradient%20descent%20is%20an,used%20in%20machine%20learning%20applications\">this link</a>\n",
    "\n",
    "# Introduction #\n",
    "\n",
    "In this exercise you'll train a neural network on the *Fuel Economy* dataset and then explore the effect of the learning rate and batch size on SGD.\n",
    "\n",
    "When you're ready, run this next cell to set everything up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd68497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4026e98",
   "metadata": {},
   "source": [
    "In the Fuel Economy dataset your task is to predict the fuel economy of an automobile given features like its type of engine or the year it was made.\n",
    "\n",
    "First load the dataset by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55e4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d6669d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EngDispl</th>\n",
       "      <th>NumCyl</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>FE</th>\n",
       "      <th>AirAspirationMethod</th>\n",
       "      <th>NumGears</th>\n",
       "      <th>TransLockup</th>\n",
       "      <th>TransCreeperGear</th>\n",
       "      <th>DriveDesc</th>\n",
       "      <th>IntakeValvePerCyl</th>\n",
       "      <th>ExhaustValvesPerCyl</th>\n",
       "      <th>CarlineClassDesc</th>\n",
       "      <th>VarValveTiming</th>\n",
       "      <th>VarValveLift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>8</td>\n",
       "      <td>AM6</td>\n",
       "      <td>28.0198</td>\n",
       "      <td>NaturallyAspirated</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TwoWheelDriveRear</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2Seaters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>8</td>\n",
       "      <td>M6</td>\n",
       "      <td>25.6094</td>\n",
       "      <td>NaturallyAspirated</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TwoWheelDriveRear</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2Seaters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.2</td>\n",
       "      <td>8</td>\n",
       "      <td>M6</td>\n",
       "      <td>26.8000</td>\n",
       "      <td>NaturallyAspirated</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AllWheelDrive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2Seaters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2</td>\n",
       "      <td>8</td>\n",
       "      <td>AM6</td>\n",
       "      <td>25.0451</td>\n",
       "      <td>NaturallyAspirated</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AllWheelDrive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2Seaters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>10</td>\n",
       "      <td>AM6</td>\n",
       "      <td>24.8000</td>\n",
       "      <td>NaturallyAspirated</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AllWheelDrive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2Seaters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EngDispl  NumCyl Transmission       FE AirAspirationMethod  NumGears  \\\n",
       "0       4.7       8          AM6  28.0198  NaturallyAspirated         6   \n",
       "1       4.7       8           M6  25.6094  NaturallyAspirated         6   \n",
       "2       4.2       8           M6  26.8000  NaturallyAspirated         6   \n",
       "3       4.2       8          AM6  25.0451  NaturallyAspirated         6   \n",
       "4       5.2      10          AM6  24.8000  NaturallyAspirated         6   \n",
       "\n",
       "   TransLockup  TransCreeperGear          DriveDesc  IntakeValvePerCyl  \\\n",
       "0            1                 0  TwoWheelDriveRear                  2   \n",
       "1            1                 0  TwoWheelDriveRear                  2   \n",
       "2            1                 0      AllWheelDrive                  2   \n",
       "3            1                 0      AllWheelDrive                  2   \n",
       "4            0                 0      AllWheelDrive                  2   \n",
       "\n",
       "   ExhaustValvesPerCyl CarlineClassDesc  VarValveTiming  VarValveLift  \n",
       "0                    2         2Seaters               1             0  \n",
       "1                    2         2Seaters               1             0  \n",
       "2                    2         2Seaters               1             0  \n",
       "3                    2         2Seaters               1             0  \n",
       "4                    2         2Seaters               1             0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel = pd.read_csv('data/fuel.csv')\n",
    "fuel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d8296df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1107 entries, 0 to 1106\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   EngDispl             1107 non-null   float64\n",
      " 1   NumCyl               1107 non-null   int64  \n",
      " 2   Transmission         1107 non-null   object \n",
      " 3   FE                   1107 non-null   float64\n",
      " 4   AirAspirationMethod  1107 non-null   object \n",
      " 5   NumGears             1107 non-null   int64  \n",
      " 6   TransLockup          1107 non-null   int64  \n",
      " 7   TransCreeperGear     1107 non-null   int64  \n",
      " 8   DriveDesc            1107 non-null   object \n",
      " 9   IntakeValvePerCyl    1107 non-null   int64  \n",
      " 10  ExhaustValvesPerCyl  1107 non-null   int64  \n",
      " 11  CarlineClassDesc     1107 non-null   object \n",
      " 12  VarValveTiming       1107 non-null   int64  \n",
      " 13  VarValveLift         1107 non-null   int64  \n",
      "dtypes: float64(2), int64(8), object(4)\n",
      "memory usage: 121.2+ KB\n"
     ]
    }
   ],
   "source": [
    "fuel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "359e963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fuel.copy()\n",
    "# Remove target\n",
    "y = X.pop('FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "103d87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(sparse=False), make_column_selector(dtype_include=object)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cd36f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "y = np.log(y) # log transform target instead of standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac91e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [50]\n"
     ]
    }
   ],
   "source": [
    "input_shape = [X.shape[1]]\n",
    "print(\"Input shape: {}\".format(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c827037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913643</td>\n",
       "      <td>1.068005</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>-0.226455</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.43492</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913643</td>\n",
       "      <td>1.068005</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>-0.226455</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.43492</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530594</td>\n",
       "      <td>1.068005</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>-0.226455</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.43492</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.530594</td>\n",
       "      <td>1.068005</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>-0.226455</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.43492</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.296693</td>\n",
       "      <td>2.120794</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>-1.458464</td>\n",
       "      <td>-0.226455</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.43492</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5        6   \\\n",
       "0  0.913643  1.068005  0.524148  0.685653 -0.226455  0.391659  0.43492   \n",
       "1  0.913643  1.068005  0.524148  0.685653 -0.226455  0.391659  0.43492   \n",
       "2  0.530594  1.068005  0.524148  0.685653 -0.226455  0.391659  0.43492   \n",
       "3  0.530594  1.068005  0.524148  0.685653 -0.226455  0.391659  0.43492   \n",
       "4  1.296693  2.120794  0.524148 -1.458464 -0.226455  0.391659  0.43492   \n",
       "\n",
       "         7         8    9   ...   40   41   42   43   44   45   46   47   48  \\\n",
       "0  0.463841 -0.447941  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.463841 -0.447941  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.463841 -0.447941  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.463841 -0.447941  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.463841 -0.447941  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    49  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X[:10,:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "691bb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(128, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee1532",
   "metadata": {},
   "source": [
    "# 1) Add Loss and Optimizer\n",
    "\n",
    "Before training the network we need to define the loss and optimizer we'll use. Using the model's `compile` method, add the Adam optimizer and MAE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a63e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5e186",
   "metadata": {},
   "source": [
    "# 2) Train Model\n",
    "\n",
    "Once you've defined the model and compiled it with a loss and optimizer you're ready for training. Train the network for 200 epochs with a batch size of 128. The input data is `X` with target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f65fc12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 3ms/step - loss: 2.6574\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9751\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5865\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3379\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2216\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1723\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1329\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1107\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0959\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0868\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0799\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0729\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0676\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0639\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0661\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0593\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0589\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0539\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0526\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0523\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0482\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0466\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0540\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0452\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0464\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0524\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0497\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0472\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0443\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0414\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0385\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0380\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.040 - 0s 4ms/step - loss: 0.0424\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0466\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0473\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0414\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0381\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0371\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0364\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0401\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0459\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0449\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0341\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0391\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0400\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0395\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0450\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0358\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0368\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0415\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0445\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0365\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0325\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0341\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0331\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0357\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0367\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0397\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0357\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0420\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0405\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0443\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0469\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0421\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0350\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0364\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0343\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0326\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0339\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0302\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0308\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0396\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0343\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0383\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0369\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0309\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0307\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0364\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0347\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0333\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0463\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0386\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0328\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0308\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0284\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0289A: 0s - loss: 0.028\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0315\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0388\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0386\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0332\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0297\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0299\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0310\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0350\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0335\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0328\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0291\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0334\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0309\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0275\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.031 - 0s 3ms/step - loss: 0.0290\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0315\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0297\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0354\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0289\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0313\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0310\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0294\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0284\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0287\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0323\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0306\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0294\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0346\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0325\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0317\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0346\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0342\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0311\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0312\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0304\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0337\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0402\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0369\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0333\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0282\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0288\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0318\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0307\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0320\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0282\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0320\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0335\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0368\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0413\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0343\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0276\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0276\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0281\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0304\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0334\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0368\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0395\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0346\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0307\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0318\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0286\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0292\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0307\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0364\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0403\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0368\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0399\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.021 - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0282\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0261\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0289\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0261\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0321\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0345\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0360\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0323\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0354\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0296\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0303\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0305\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0275\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0289\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0292\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0358\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0397\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0363\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0322\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0288\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0352\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0291\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0290\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0295\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=128, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc1237",
   "metadata": {},
   "source": [
    "The last step is to look at the loss curves and evaluate the training. Run the cell below to get a plot of the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "102ad82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5. You can change this to get a different view.\n",
    "history_df.loc[10:, ['loss']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86be5e",
   "metadata": {},
   "source": [
    "# 3) Evaluate Training\n",
    "\n",
    "If you trained the model longer, would you expect the loss to decrease further?\n",
    "\n",
    "Answer: This depends on how the loss has evolved during training: if the learning curves have levelled off, there won't usually be any advantage to training for additional epochs. Conversely, if the loss appears to still be decreasing, then training for longer could be advantageous.\n",
    "\n",
    "With the learning rate and the batch size, you have some control over:\n",
    "- How long it takes to train a model\n",
    "- How noisy the learning curves are\n",
    "- How small the loss becomes\n",
    "\n",
    "To get a better understanding of these two parameters, we'll look at the linear model, our ppsimplest neural network. Having only a single weight and a bias, it's easier to see what effect a change of parameter has.\n",
    "\n",
    "The next cell will generate an animation like the one in the tutorial. Change the values for `learning_rate`, `batch_size`, and `num_examples` (how many data points) and then run the cell. (It may take a moment or two.) Try the following combinations, or try some of your own:\n",
    "\n",
    "| `learning_rate` | `batch_size` | `num_examples` |\n",
    "|-----------------|--------------|----------------|\n",
    "| 0.05            | 32           | 256            |\n",
    "| 0.05            | 2            | 256            |\n",
    "| 0.05            | 128          | 256            |\n",
    "| 0.02            | 32           | 256            |\n",
    "| 0.2             | 32           | 256            |\n",
    "| 1.0             | 32           | 256            |\n",
    "| 0.9             | 4096         | 8192           |\n",
    "| 0.99            | 4096         | 8192           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fef64668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# YOUR CODE HERE: Experiment with different values for the learning rate, batch size, and number of examples\\nlearning_rate = 0.05\\nbatch_size = 32\\nnum_examples = 256\\n\\nanimate_sgd(\\n    learning_rate=learning_rate,\\n    batch_size=batch_size,\\n    num_examples=num_examples,\\n    # You can also change these, if you like\\n    steps=50, # total training steps (batches seen)\\n    true_w=3.0, # the slope of the data\\n    true_b=2.0, # the bias of the data\\n)\\n\\n# this animation works in the kaggle plataform'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# YOUR CODE HERE: Experiment with different values for the learning rate, batch size, and number of examples\n",
    "learning_rate = 0.05\n",
    "batch_size = 32\n",
    "num_examples = 256\n",
    "\n",
    "animate_sgd(\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_examples=num_examples,\n",
    "    # You can also change these, if you like\n",
    "    steps=50, # total training steps (batches seen)\n",
    "    true_w=3.0, # the slope of the data\n",
    "    true_b=2.0, # the bias of the data\n",
    ")\n",
    "\n",
    "# this animation works in the kaggle plataform'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25014c10",
   "metadata": {},
   "source": [
    "# 4) Learning Rate and Batch Size\n",
    "\n",
    "What effect did changing these parameters have? After you've thought about it, run the cell below for some discussion.\n",
    "\n",
    "You probably saw that smaller batch sizes gave noisier weight updates and loss curves. This is because each batch is a small sample of data and smaller samples tend to give noisier estimates. Smaller batches can have an \"averaging\" effect though which can be beneficial.\n",
    "\n",
    "Smaller learning rates make the updates smaller and the training takes longer to converge. Large learning rates can speed up training, but don't \"settle in\" to a minimum as well. When the learning rate is too large, the training can fail completely. (Try setting the learning rate to a large value like 0.99 to see this.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
