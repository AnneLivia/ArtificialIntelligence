{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to test your models.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Machine learning is an iterative process.\n",
    "\n",
    "You will face choices about what predictive variables to use, what types of models to use, what arguments to supply to those models, etc. So far, you have made these choices in a data-driven way by measuring model quality with a validation (or holdout) set.\n",
    "\n",
    "But there are some drawbacks to this approach. To see this, imagine you have a dataset with 5000 rows. You will typically keep about 20% of the data as a validation dataset, or 1000 rows. But this leaves some random chance in determining model scores. That is, a model might do well on one set of 1000 rows, even if it would be inaccurate on a different 1000 rows.\n",
    "\n",
    "At an extreme, you could imagine having only 1 row of data in the validation set. If you compare alternative models, which one makes the best predictions on a single data point will be mostly a matter of luck!\n",
    "\n",
    "In general, the larger the validation set, the less randomness (aka \"noise\") there is in our measure of model quality, and the more reliable it will be. Unfortunately, we can only get a large validation set by removing rows from our training data, and smaller training datasets mean worse models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is cross-validation?\n",
    "\n",
    "In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.\n",
    "\n",
    "For example, we could begin by dividing the data into 5 pieces, each 20% of the full dataset. In this case, we say that we have broken the data into 5 \"folds\".\n",
    "\n",
    "<img src=\"https://i.imgur.com/9k60cVA.png\"/>\n",
    "\n",
    "Then, we run one experiment for each fold:\n",
    "\n",
    "- In Experiment 1, we use the first fold as a validation (or holdout) set and everything else as training data. This gives us a measure of model quality based on a 20% holdout set.\n",
    "- In Experiment 2, we hold out data from the second fold (and use everything except the second fold for training the model). The holdout set is then used to get a second estimate of model quality.\n",
    "- We repeat this process, using every fold once as the holdout set. Putting this together, 100% of the data is used as holdout at some point, and we end up with a measure of model quality that is based on all of the rows in the dataset (even if we don't use all rows simultaneously).\n",
    "\n",
    "\n",
    "# When should you use cross-validation?\n",
    "\n",
    "Cross-validation gives a more accurate measure of model quality, which is especially important if you are making a lot of modeling decisions. However, it can take longer to run, because it estimates multiple models (one for each fold).\n",
    "\n",
    "So, given these tradeoffs, when should you use each approach?\n",
    "\n",
    "For small datasets, where extra computational burden isn't a big deal, you should run cross-validation.\n",
    "For larger datasets, a single validation set is sufficient. Your code will run faster, and you may have enough data that there's little need to re-use some of it for holdout.\n",
    "There's no simple threshold for what constitutes a large vs. small dataset. But if your model takes a couple minutes or less to run, it's probably worth switching to cross-validation.\n",
    "\n",
    "Alternatively, you can run cross-validation and see if the scores for each experiment seem close. If each experiment yields the same results, a single validation set is probably sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "melb = pd.read_csv('dataset/melb_data.csv')\n",
    "y = melb['Price']\n",
    "# Select subset of predictors\n",
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "x = melb[cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rooms         13580 non-null  int64  \n",
      " 1   Distance      13580 non-null  float64\n",
      " 2   Landsize      13580 non-null  float64\n",
      " 3   BuildingArea  7130 non-null   float64\n",
      " 4   YearBuilt     8205 non-null   float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 530.6 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a pipeline that uses an imputer to fill in missing values and a random forest model to make predictions.\n",
    "\n",
    "While it's possible to do cross-validation without pipelines, it is quite difficult! Using a pipeline will make the code remarkably straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cols_transform = SimpleImputer()\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', cols_transform), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way kaggle does\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators=50,\n",
    "                                                              random_state=0))\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the cross-validation scores with the cross_val_score() function from scikit-learn. We set the number of folds with the cv parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scores:\n",
      " [301628.7893587  303164.4782723  287298.331666   236061.84754543\n",
      " 260383.45111427]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, x, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring parameter chooses a measure of model quality to report: in this case, we chose negative mean absolute error (MAE). The docs for scikit-learn show a list of options.\n",
    "\n",
    "It is a little surprising that we specify negative MAE. Scikit-learn has a convention where all metrics are defined so a high number is better. Using negatives here allows them to be consistent with that convention, though negative MAE is almost unheard of elsewhere.\n",
    "\n",
    "We typically want a single measure of model quality to compare alternative models. So we take the average across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score (across experiments):\n",
      "277707.3795913405\n"
     ]
    }
   ],
   "source": [
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Using cross-validation yields a much better measure of model quality, with the added benefit of cleaning up our code: note that we no longer need to keep track of separate training and validation sets. So, especially for small datasets, it's a good improvement!\n",
    "\n",
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_train = pd.read_csv('dataset/home_data_train.csv', index_col='Id')\n",
    "data_full_test = pd.read_csv('dataset/home_data_test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing target, separate target from predictors\n",
    "data_full_train.dropna(subset=['SalePrice'], axis=0, inplace=True)\n",
    "y = data_full_train['SalePrice']\n",
    "x = data_full_train.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                          \n",
       "1           60         65.0     8450            7            5       2003   \n",
       "2           20         80.0     9600            6            8       1976   \n",
       "3           60         68.0    11250            7            5       2001   \n",
       "4           70         60.0     9550            7            5       1915   \n",
       "5           60         84.0    14260            8            5       2000   \n",
       "\n",
       "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                    ...               \n",
       "1           2003       196.0         706           0  ...         548   \n",
       "2           1976         0.0         978           0  ...         460   \n",
       "3           2002       162.0         486           0  ...         608   \n",
       "4           1970         0.0         216           0  ...         642   \n",
       "5           2000       350.0         655           0  ...         836   \n",
       "\n",
       "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "Id                                                                             \n",
       "1            0           61              0          0            0         0   \n",
       "2          298            0              0          0            0         0   \n",
       "3            0           42              0          0            0         0   \n",
       "4            0           35            272          0            0         0   \n",
       "5          192           84              0          0            0         0   \n",
       "\n",
       "    MiscVal  MoSold  YrSold  \n",
       "Id                           \n",
       "1         0       2    2008  \n",
       "2         0       5    2007  \n",
       "3         0       9    2008  \n",
       "4         0       2    2006  \n",
       "5         0      12    2008  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numeric columns only\n",
    "cols_num = [col for col in x.columns if x[col].dtype in ['float64', 'int64']]\n",
    "x = x[cols_num].copy()\n",
    "test = data_full_test[cols_num].copy()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned how to build pipelines with scikit-learn. For instance, the pipeline below will use SimpleImputer() to replace missing values in the data, before using RandomForestRegressor() to train a random forest model to make predictions. We set the number of trees in the random forest model with the n_estimators parameter, and setting random_state ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators=50, random_state=0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have also learned how to use pipelines in cross-validation. The code below uses the cross_val_score() function to obtain the mean absolute error (MAE), averaged across five different folds. Recall we set the number of folds with the cv parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 18276.410356164386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = -1 * cross_val_score(my_pipeline, x, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Write a useful function\n",
    "\n",
    "In this exercise, you'll use cross-validation to select parameters for a machine learning model.\n",
    "\n",
    "Begin by writing a function `get_score()` that reports the average (over three cross-validation folds) MAE of a machine learning pipeline that uses:\n",
    "- the data in `X` and `y` to create folds,\n",
    "- `SimpleImputer()` (with all parameters left as default) to replace missing values, and\n",
    "- `RandomForestRegressor()` (with `random_state=0`) to fit a random forest model.\n",
    "\n",
    "The `n_estimators` parameter supplied to `get_score()` is used when setting the number of trees in the random forest model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\"\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()), \n",
    "                                  ('model', RandomForestRegressor(n_estimators = n_estimators, random_state=0))])\n",
    "   \n",
    "    scores = -1 * cross_val_score(my_pipeline, X=x, y=y, cv=3, scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle solution\n",
    "\n",
    "def get_score(n_estimators):\n",
    "\n",
    "    my_pipeline = Pipeline(steps=[\n",
    "    \n",
    "        ('preprocessor', SimpleImputer()),\n",
    "        \n",
    "        ('model', RandomForestRegressor(n_estimators, random_state=0))\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                                  cv=3,\n",
    "                                  scoring='neg_mean_absolute_error')\n",
    "                                  \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test different parameter values\n",
    "\n",
    "Now, you will use the function that you defined in Step 1 to evaluate the model performance corresponding to eight different values for the number of trees in the random forest: 50, 100, 150, ..., 300, 350, 400.\n",
    "\n",
    "Store your results in a Python dictionary `results`, where `results[i]` is the average MAE returned by `get_score(i)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: 18353.8393511688,\n",
       " 100: 18395.2151680032,\n",
       " 150: 18288.730020956387,\n",
       " 200: 18248.345889801505,\n",
       " 250: 18255.26922247291,\n",
       " 300: 18275.241922621914,\n",
       " 350: 18270.29183308043,\n",
       " 400: 18270.197974402367}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i in range(50, 401, 50):\n",
    "    results[i] = get_score(i)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Solution\n",
    "\n",
    "results = {} \n",
    "\n",
    "for i in range(1,9):\n",
    "\n",
    "    results[50*i] = get_score(50*i)\n",
    "    \n",
    "Use the next cell to visualize your results from Step 2. Run the code without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VfWd//HXJztrEsgiEhBZhKBChIC2LliI1i4OOtpaqy3T+pOOdpMu49hOdazTTt1GW6fqMOqotdpWx6XTahWQam3BGpBNFomIEENJIGwBAlk+vz/uCVySQEK2c2/u+/l43EfO/Z7vufdzDySf+13O+Zq7IyIiEi0p7ABERCT2KDmIiEgLSg4iItKCkoOIiLSg5CAiIi0oOYiISAtKDiIi0oKSg4iItKDkICIiLaS0p5KZPQJ8Gqh099OCsiLgQSADqAeud/e/Rh0zBVgMXOHuzwRls4B/Car8m7s/FpRPBh4F+gAvAt/0Ni7dzsnJ8REjRrTvU4qICABLlizZ5u65bdWz9tw+w8zOA2qAx6OSwyvAPe7+kpl9Evgndz8/2JcMzANqgUfc/RkzGwSUAsWAA0uAye6+w8z+CnyTSDJ5EfiZu790rJiKi4u9tLS0zdhFROQwM1vi7sVt1WtXt5K7vw5UNy8GBgbbmUBF1L6vA/8LVEaVfRyY5+7V7r6DSPK4yMyGAAPdfVHQWngcuKQ9cYmISPdoV7fSUdwAvGxmdxFJMh8FMLOhwKXAdGBKVP2hwOao5+VB2dBgu3m5iIiEpDMD0tcBc9x9GDAHeDgovxe40d0bmtW3Vl7Dj1HegpnNNrNSMyutqqrqYNgiItKWziSHWcCzwfbTwNRguxj4lZltBC4H7jezS4i0CIZFHV9ApCuqPNhuXt6Cu89192J3L87NbXM8RUREOqgzyaECmBZsTwfWA7j7ye4+wt1HAM8QmcX0PPAycKGZZZtZNnAh8LK7bwH2mNlZZmbAF4EXOhGXiIh0Ununsj4FnA/kmFk5cAtwLfBTM0shMitp9rFew92rzew24K2g6Ifu3jTIfR2Hp7K+FDxERCQk7ZrKGos0lVVE5Ph16VRWCUdtXQO/WLSR2rrmY/siIt2rM1NZpRu5O997diXPvv0haSlJXDFleNghiUgCUcshRj3x5iaefftDkgzmr6ls+wARkS6klkMMWrppBz/8v3f42Nhchmb34Zkl5dTWNZCRmhx2aCKSINRyiDHbag5w/RNLGZLZh3uvOIMLx59AbV0jf3lvW9ihiUgCUXKIIfUNjXz9ybfZse8gD1w9icy+qZw5chD901OYt1pdSyLSc5QcYsidr6xj0Ybt/OjS0zn1xEwA0lOSOe+UHBas2UpjY3xOOxaR+KPkECP+sGoL//XaBq46cziXTy44Yl9JYT6Vew6wqmJXSNGJSKJRcogB71XV8J2nVzBxWBY3Xzy+xf6Pjc2LzFpavTWE6EQkESk5hGzvgXr+8RdLSEtJ4oGrJpGe0nJGUna/NIpPGsQ8TWkVkR6i5BAid+fG/13Be1U13HflGZyY1eeodUvG57Fmy24+3Lm/ByMUkUSl5BCiR/68kd+t2MJ3Pz6Os0fnHLNuSWE+AAvWqGtJRLqfkkNI/vp+NT9+cQ0fPzWff5w2ss36I3P7MzKnH/M07iAiPUDJIQSVu2v56pNLOWlQX+78zEQiy1i0rWR8Pos3bGdPbV03RygiiU7JoYfVNTRy/S+XUlNbz4NfmMzAjNR2H1tSmE9dg/On9bpaWkS6l5JDD/v3F9dS+sEOfnLZ6ZySP+C4jp00PIusvqma0ioi3U7JoQf9dnkFj/z5fb509ghmFg097uNTkpOYPjaPhesqqW9o7IYIRUQilBx6yLtb93DjMysoPimb732ysMOvUzI+nx376li6aWcXRicicqR2JQcze8TMKs1sVVRZkZktNrNlZlZqZlOD8plmtiKq/JyoY+4ws3fMbI2Z/cyCkVgzm2xmK82sLLq8t9hdW8c//mIJ/TNSuP+qSaQmdzwnnzsmh9RkY76mtIpIN2rvX6lHgYuald0B3OruRcDNwXOABcDEoPzLwEMAZvZR4GxgAnAaMAWYFhzzADAbGBM8mr9X3HJ3vvOb5XxQvY+ff34SeQMzOvV6AzJSOWvkYCUHEelW7UoO7v46UN28GBgYbGcCFUHdGndvun1ov6BeU/0MIA1IB1KBrWY2BBjo7ouC4x4HLunYx4k9D762gVdWb+V7nyxk6smDuuQ1Lxifz4aqvbxXVdMlryci0lxnxhxuAO40s83AXcBNTTvM7FIzWwv8nkjrAXdfBCwEtgSPl919DTAUKI963fKgLO79uWwbd768lk9PGMKXzx7RZa87fVweoKulRaT7dCY5XAfMcfdhwBzg4aYd7v6cu48j0gK4DcDMRgOFQAGRP/7Tzew8oLXxhVYXLjCz2cE4RmlVVVUnQu9+FTv38/Wn3mZUbn9uv2xCuy90a4+C7L4UDhmotaVFpNt0JjnMAp4Ntp8GpjavEHRHjTKzHOBSYHHQ7VQDvAScRaSlEL2AQQFBF1UrrzfX3YvdvTg3N7cToXevA/UNXP/LpRysb+TBL0ymX3rXL9V9QWEepRur2bH3YJe/tohIZ5JDBYcHlKcD6yHSQoiahTSJyBjDdmATMM3MUswsNTh2jbtvAfaY2VnBcV8EXuhEXKG77XerWbZ5J3d9ZgKjcvt3y3vMKMyn0WHhOrUeRKTrtesrrZk9BZwP5JhZOXALcC3wUzNLAWqJzDYCuAz4opnVAfuBK9zdzewZIklkJZFuoz+4+/8Fx1xHZEZUHyItipc6/9HC8cyScp5YvImvTBvJRacN6bb3OX1oJnkD0lmwppK/n1TQ9gEiIsehXcnB3a88yq7JrdS9Hbi9lfIG4CtHef1SItNb49o7Fbv4/nMr+cjIwXz3wrHd+l5JScaMwjz+b/kWDtQ3tLpIkIhIR+kK6S6ya18d//jEErL7pnHf588gpRMXurVXSWE+NQfqeXND81nGIiKdo+TQBRobnRt+/TZ/21XL/VdPIqd/eo+879mjc8hITdKUVhHpckoOXeC+V8tYuK6Kmy8+lUnDs3vsfTNSkzlndC7z11Ry+LpDEZHOU3LopD+uq+TeBe/y95OGcvWZw3v8/S8Yn8eHO/ezZsueHn9vEem9lBw6YXP1Pr75q2WMO2EgP7rk9C690K29po/Lx0xXS4tI11Jy6KDaugau++USGt158OpJ9EkLZ7ZQ7oB0JhZk6UZ8ItKllBw6wN35wfOrWPXhbu69ooiTBvcLNZ4LxuezvHwXW3fXhhqHiPQeSg4d8Ku3NvP0knK+MX00Mwrzww6HkiCGV9fqamkR6RpKDsdp+ead3PLCO5x3Si7fLDkl7HAAOCW/PwXZfbS2tIh0GSWH41C99yDXPbGE3AHp/PSKIpKTYmPBOjOjpDCfN8q2sf9gQ9jhiEgvoOTQTg2Nzjeeepttew/y4NWTye6XFnZIR7hgfD4H6ht5o2xb2KGISC+g5NBO98x7lzfKtvFvM0/j9ILMsMNpYcqIQQxIT1HXkoh0CSWHdpi3eiv/ubCMK6cO47NThoUdTqvSUpKYNjaXBWsraWzU1dIi0jlKDm14f9tevvXrZUwoyOSWi08NO5xjumB8PttqDrC8fGfYoYhInFNyOIZ9B+u57oklJCcb9181iYzU2L4t9vmn5JGcZLogTkQ6TcnhKNydm55dybqte/jZ586gILtv2CG1KbNvKlNGZDN/ta53EJHOUXI4iscXfcALyyr49gWncN4psbtedXMlhfms27qHzdX7wg5FROKYkkMrlnxQzW2/W01JYR7Xnz867HCOS9PV0upaEpHOaDM5mNkjZlZpZquiyorMbLGZLTOzUjObGpTPNLMVUeXnRB0z3MxeMbM1ZrbazEYE5Seb2Ztmtt7Mfm1moV5AULXnANf/cilDs/tw92eLSIqRC93aa0ROP0bn9VdyEJFOaU/L4VHgomZldwC3unsRcHPwHGABMDEo/zLwUNQxjwN3unshMBVo6hi/HbjH3ccAO4BrOvA5ukR9QyNfe3Ipu/bX8eDVk8nskxpWKJ1SUpjPmxuq2V1bF3YoIhKn2kwO7v460HyRYgcGBtuZQEVQt8YPL0nWL6iHmY0HUtx9XlS9fRZZAGE68ExwzGPAJR3/OJ1zx8vrePP9av7970+ncMjAtg+IUSWFedQ3Oq+tqwo7FBGJUx0dc7gBuNPMNgN3ATc17TCzS81sLfB7Iq0HgFOAnWb2rJm9bWZ3mlkyMBjY6e71Qb1yYGgHY+qUF1duYe7rG5j1kZO49IyCMELoMmcMz2ZQvzR1LYlIh3U0OVwHzHH3YcAc4OGmHe7+nLuPI9ICuC0oTgHOBb4DTAFGAv8AtNahf9TLe81sdjCWUVpV1XXfissq9/Ddp5czaXgW3//U+C573bAkJxnTx+WxcG0ldQ2NYYcjInGoo8lhFvBssP00kTGEIwTdUaPMLIdIi+Btd98QtBKeByYB24AsM0sJDisg6KJqjbvPdfdidy/Oze2a6aU1B+r5yi+W0CctmfuvmkxaSu+YwFVSmMfu2npKN+4IOxQRiUMd/UtYAUwLtqcD6wHMbHQwjoCZTQLSgO3AW0C2meVGHbM6GJ9YCFwelM8CXuhgTMfN3fmnZ5azcfs+7rtyEidkZvTUW3e7c8fkkpacpK4lEemQ9kxlfQpYBIw1s3Izuwa4FrjbzJYDPwZmB9UvA1aZ2TLg58AVHtFApEtpgZmtJNKd9N/BMTcC3zKzMiJjEIe6qLrbQ396nxdX/o0bLxrLR0YN7qm37RH90lP46OjBzF+zlcNzBERE2ielrQrufuVRdk1upe7tRKamtvY684AJrZRvoJVuqe62eMN2fvKHtXzitBO49tyRPf32PWJGYT4/eH4V71XVMDpvQNjhiEgc6R0d7Mfpb7tq+dqTSxkxuC93fmYiQU9Yr1NSmAfAPN1rSUSOU8Ilh4P1jXz1yaXsP9jAf31hMv3T22w8xa0hmX04behAFmjcQUSOU8Ilhx+/uIYlH+zgjssnJkRXy4xx+SzZtIPtNQfCDkVE4khCJQd3Z0hmBl+ZNpJPTRgSdjg94oLx+bjDq2vVtSQi7dd7+1RaYWZ8ZdqosMPoUaeeOJATBmawYE0lnymOzSVORST2JFTLIRGZGTMK83h9fRW1dQ1hhyMicULJIQGUjM9n38EGFm3YHnYoIhInlBwSwEdGDqZvWrJmLYlIuyk5JICM1GTOHZPD/NWVulpaRNpFySFBlBTm87fdtbxTsTvsUEQkDig5JIjp4/Iw09rSItI+Sg4JYnD/dCYNz1ZyEJF2UXJIICWF+az6cDdbdu0POxQRiXFKDgnkgvGRG/EtWKOrpUXk2JQcEsio3P6cNLivupZEpE1KDgnEzCgpzOcvZdvZe6A+7HBEJIYpOSSYksJ8DjY08qf128IORURimJJDgikekc3AjBR1LYnIMbUrOZjZI2ZWaWarosqKzGyxmS0zs1IzmxqUzzSzFVHl5zR7rYFm9qGZ/WdU2WQzW2lmZWb2M+utS7PFgNTkJD42Lo9X11bS0KirpUWkde1tOTwKXNSs7A7gVncvAm4OngMsACYG5V8GHmp23G3Aa83KHgBmA2OCR/P3ki5UUphP9d6DLNu8I+xQRCRGtSs5uPvrQHXzYmBgsJ0JVAR1a/zwDXz6BfWASAsByAdeiSobAgx090XBcY8Dlxz/R5H2mjY2l5Qk09rSInJUnRlzuAG408w2A3cBNzXtMLNLzWwt8HsirQfMLAm4G/hus9cZCpRHPS8PyqSbDMxI5cyRgzTuICJH1ZnkcB0wx92HAXOAh5t2uPtz7j6OSAvgtqD4euBFd9/c7HVaG19otTPczGYH4xilVVVVnQhdSgrzKausYeO2vWGHIiIxqDPJYRbwbLD9NDC1eYWgO2qUmeUAHwG+ZmYbibQ0vmhmPyHSUiiIOqyAoIuqldeb6+7F7l6cm5vbidClpDAf0I34RKR1nUkOFcC0YHs6sB7AzEY3zTYys0lAGrDd3a9y9+HuPgL4DvC4u/+zu28B9pjZWcFxXwRe6ERc0g7DBvVlbP4AJQcRaVVKeyqZ2VPA+UCOmZUDtwDXAj81sxSglshsI4DLiLQK6oD9wBXe9goz1xGZEdUHeCl4SDcrGZ/Hg69tYNe+OjL7poYdjojEEIvXlcGKi4u9tLQ07DDi2tJNO/j7+//CTz9XxMwizQEQSQRmtsTdi9uqpyukE1hRQRY5/dOYt1pdSyJyJCWHBJaUZMwYl89r71ZxsL4x7HBEJIYoOSS4GYV57Kmt562Nza9xFJFEpuSQ4M4Zk0N6SpK6lkTkCEoOCa5vWgpnj85hwdqtxOvkBBHpekoOQklhPpur9/Pu1pqwQxGRGKHkIMwojKwtrQviRKSJkoOQPzCDCQWZSg4icoiSgwCRrqVlm3dSuac27FBEJAYoOQgQSQ7usHCt1ngQESUHCRQOGcCJmRnMX6PkICJKDhIwM0rG5/On9VXU1jWEHY6IhEzJQQ4pKcyntq6RP5dtCzsUEQmZkoMccubIQfRLS1bXkogoOchh6SnJTBuby4I1W2ls1NXSIolMyUGOUFKYT+WeA6z8cFfYoYhIiJQc5AgfG5tHksECXRAnktCUHOQI2f3SKD5pEPM07iCS0NpMDmb2iJlVmtmqqLIiM1tsZsvMrNTMpgblM81sRVT5OVH1F5nZO8H+K6Je62Qze9PM1pvZr80srTs+qLRfyfg81mzZTfmOfWGHIiIhaU/L4VHgomZldwC3unsRcHPwHGABMDEo/zLwUFC+D/iiu58avNa9ZpYV7LsduMfdxwA7gGs6+Fmki8wozAfgVV0tLZKw2kwO7v460HyZMAcGBtuZQEVQt8YPLwrQL6iHu7/r7uuD7QqgEsg1MwOmA88ExzwGXNLhTyNdYlRuf0bm9NMCQCIJLKWDx90AvGxmdxFJMB9t2mFmlwL/DuQBn2p+YNAFlQa8BwwGdrp7fbC7HBh6tDc1s9nAbIDhw4d3MHRpj5Lx+fzPn99nT20dAzJSww5HRHpYRwekrwPmuPswYA7wcNMOd3/O3ccRaQHcFn2QmQ0BfgF8yd0bAWvltY86wd7d57p7sbsX5+bmdjB0aY8Z4/Koa3D+tF5XS4skoo4mh1nAs8H208DU5hWC7qhRZpYDYGYDgd8D/+Lui4Nq24AsM2tqwRQQdFFJuCaflE1W31Tmq2tJJCF1NDlUANOC7enAegAzGx2MI2Bmk4h0H20PZiA9Bzzu7k83vUgwPrEQuDwomgW80MGYpAulJCcxfWweC9dVUt/QGHY4ItLD2jOV9SlgETDWzMrN7BrgWuBuM1sO/JhgHAC4DFhlZsuAnwNXBAngs8B5wD8E01yXmVlRcMyNwLfMrIzIGMShLioJ14zCfHbsq2Pppp1hhyIiPazNAWl3v/Iouya3Uvd2IlNTm5c/ATxxlNffQCvdUhK+807JITXZmL9mK1NPHhR2OCLSg3SFtBzVgIxUzho5WGtLiyQgJQc5ppLCfDZU7eW9qpqwQxGRHqTkIMc0ozAP0I34RBKNkoMcU0F2XwqHDNQCQCIJRslB2lRSmEfpxmp27D0Ydigi0kOUHKRNJYX5NDosXKfWg0iiUHKQNp0+NJO8AeksUNeSSMJQcpA2JSUZMwrzeO3dKg7UN4Qdjoj0ACUHaZeSwnxqDtTz5obmd28Xkd5IyUHa5ezROWSkJmlKq0iCUHKQdslITeac0bnMX1PJ4fWcRKS3UnKQdrtgfB4f7tzPmi17wg5FRLqZkoO02/Rx+ZjpammRRKDkIO2WOyCdiQVZuhGfSAJQcpDjcsH4fJaX72Lr7tqwQxGRbqTkIMelpDAfgFfX6oI4kd5MyUGOyyn5/SnI7qO1pUV6OSUHOS5mRklhPm+UbWP/QV0tLdJbtSs5mNkjZlZpZquiyorMbHGwHnSpmU0Nymea2Yqo8nOijpllZuuDx6yo8slmttLMyszsZ2ZmXfkhpWtdMD6fA/WNvFG2LexQRKSbtLfl8ChwUbOyO4Bb3b0IuDl4DrAAmBiUfxl4CMDMBgG3AGcSWTP6FjPLDo55AJgNjAkezd9LYsiUEYMYkJ6iriWRXqxdycHdXwea31THgYHBdiZQEdSt8cOX0PYL6gF8HJjn7tXuvgOYB1xkZkOAge6+KDjuceCSjn4g6X5pKUlMG5vLgrWVNDbqammR3qgzYw43AHea2WbgLuCmph1mdqmZrQV+T6T1ADAU2Bx1fHlQNjTYbl7egpnNDrqqSquqqjoRunTWBePz2VZzgOXlO8MORUS6QWeSw3XAHHcfBswBHm7a4e7Pufs4Ii2A24Li1sYR/BjlLQvd57p7sbsX5+bmdiJ06azzT8kjOcl0QZxIL9WZ5DALeDbYfprIOMIRgu6oUWaWQ6RFMCxqdwGRrqjyYLt5ucSwzL6pTBmRzfzVut5BpDfqTHKoAKYF29OB9QBmNrpptpGZTQLSgO3Ay8CFZpYdDERfCLzs7luAPWZ2VnDcF4EXOhGX9JCSwnzWbd3D5up9YYciIl2svVNZnwIWAWPNrNzMrgGuBe42s+XAj4nMNgK4DFhlZsuAnwNXeEQ1kS6mt4LHD4MyiHRRPQSUAe8BL3XJp5Nu1XS1tLqWRHofi9d78xcXF3tpaWnYYSS8kv94jfyB6fzy/50Vdigi0g5mtsTdi9uqpyukpVNKCvN5c0M1u2vrwg5FRLqQkoN0SklhHvWNzmvrNLVYpDdRcpBOOWN4NoP6pWncQaSXUXKQTklOMqaPy2Ph2krqGhrDDkdEuoiSg3RaSWEeu2vrKd24I+xQRKSLKDlIp507Jpe05CR1LYn0IkoO0mn90lP46OjBzF+zlXidGi0iR1JykC4xozCfD7bv472qmrBDEZEuoOQgXaKkMA+AebrXkkivoOQgXWJIZh9OH5rJU3/dxK79uiBOJN4pOUiXueXi8VTs3M8Nv3qbBi0CJBLXlBykyxSPGMQtf3cqC9dVce/8d8MOR0Q6QclButTVZw7niuJh3PdqGX9YtSXscESkg5QcpEuZGbfOPJWJw7L49m+Ws37rnrBDEpEOUHKQLpeRmsx/XT2ZPmkpzP7FEg1Qi8QhJQfpFidkZvDA1ZPYXL1PA9QicUjJQbrNFA1Qi8QtJQfpVhqgFolPbSYHM3vEzCrNbFVUWZGZLTazZWZWamZTg/KrzGxF8PiLmU2MOmaOmb1jZqvM7CkzywjKTzazN81svZn92szSuuODSjg0QC0Sn9rTcngUuKhZ2R3Are5eBNwcPAd4H5jm7hOA24C5AGY2FPgGUOzupwHJwOeCY24H7nH3McAO4JoOfxqJSRqgFok/bSYHd38dqG5eDAwMtjOBiqDuX9y96ab+i4GCqGNSgD5mlgL0BSrMzIDpwDNBnceASzrwOSTGaYBaJL50dMzhBuBOM9sM3AXc1Eqda4CXANz9w6DeJmALsMvdXwEGAzvdvT44phwYerQ3NbPZQTdWaVWV1iyONxqgFokfHU0O1wFz3H0YMAd4OHqnmX2MSHK4MXieDcwETgZOBPqZ2dWAtfLaR/1K6e5z3b3Y3Ytzc3M7GLqE6eozh/PZ4gINUIvEuI4mh1nAs8H208DUph1mNgF4CJjp7tuD4hLgfXevcve64NiPAtuArKCrCSLdUBUdjEnigJnxw5mnaYBaJMZ1NDlUANOC7enAegAzG07kD/8X3D2632ATcJaZ9Q3GGWYAazyybNhC4PKg3izghQ7GJHFCA9Qisa89U1mfAhYBY82s3MyuAa4F7jaz5cCPgdlB9ZuJjCPc3zTNFcDd3yQy6LwUWBm879zgmBuBb5lZWXDsEV1U0jtpgFoktlm8rvlbXFzspaWlYYchnfSLxR/wg+dX8fXpo/n2hWPDDke6iLsT6SSQWGNmS9y9uK16KW1VEOlOV585nJXlO7nv1TJOPXEgF502JOyQpBN27a/jrpfX8au3NpHbP52Ruf0ZmduPUcHPkbn9GTIwg6QkJY5Yp+QgoWoaoF63tYZv/2Y5o3L7MyZ/QNhhyXFyd367vILbfreG6r0HuPSMAhrd2VBVw3NLP2TPgfpDdfukJnNyTr9DyWJUbj9G5kSSR790/UmKFepWkpjwt121fPq+NxiQkcLzXz2bzD6pYYck7fT+tr3c/MIq/rR+GxMKMvnxpadz2tDMQ/vdnao9B3ivai8bttWwoWov71VFfpbv2Ef0cNMJAzOCpNHU2ujPyJx+DM3qo9ZGF2lvt5KSg8SMtzZWc+XcxZw7JoeHZk0hWX8MYtqB+gYe/OMGfv7HMtKTk/juRWO56syTjuvfrbaugU3V+3ivsoYN2w4njfeqathTe7i1kZ6SxMk50d1Th1sbAzL0ReJ4KDlIXNIAdXz4c9k2fvD8KjZs28vFE0/kB58qJG9gRpe9vruzreYgG6oiSWNDVU2k5VFVw6bqI1sbeQPSD3VRjczpx6i8/ozK6c/Q7D76gtEKDUhLXNIAdWyr2nOAH/1+Nc8vq+CkwX157MtTmXZK19+twMzIHZBO7oB0zhw5+Ih9B+sb2VS9l7LKw91UG6pq+P2KLUdcM5OWksSIwX0ZmdOfUXmHWxojc/ur27IdlBwkpmiAOjY1NjpPvbWJ219ay/66Br4xfTTXf2w0GanJPR5LWkoSo/MGMDrvyP8X7k713oOHWhpN3VPvbt3DvDVbj7iWJqd/2hGD4dn9IisFGNA0A9cMDCN6Rq6ZHbrnT/P9h4+1qP0cmtLbtP9w/UgFa/ba0fstaj9R7zexIIs+ad177tWtJDFJA9SxY3XFbr7//Ere3rSTs0YO4t8uOZ3Ref3DDuu41DU0HjG20ZQ8NmzbS/Xeg2GHd9zmf2tah/8N1K0kca3pCuor5y7mhl+9rQHqEOw9UM+989/lkT9vJKtPKv/x2YlcesbQuLy4LTU5iVG5/RmV2/IP6o69B6k5UI87OE7T92Un0hpp+vocKW++v2k7Ut78OVHHduS1m768e9RrAJyY1XXjO0ej5CAxa8qIQdxy8Xh+8MI73Dv/XQ1Q96CX3/kb//rbd9iyq5Yrpw7jxovGkdW3dy4UaeMpAAALFUlEQVTSmN0v7VC3khym5CAx7eqzTmLlh7s0QN1Dynfs419/u5r5a7Yy7oQB/Ofnz2DySYPCDktCoOQgMU0D1D2jrqGRR954n3vnrwfge58cx5fOPpnU5I7euFninf7lJebpFt/da8kH1Vx83xv8+0trOXt0DvO/PY3Z541SYkhw+teXuND8Ft+NusV3p+3cd5Cbnl3BZQ8sYvf+OuZ+YTIPzSpmaFafsEOTGKDkIHGjaYB64boq7tEa1B3m7vzvknKm3/0avyktZ/Z5I5n3rWlceOoJYYcmMURjDhJXNEDdOWWVNfzL8ytZvKGaM4Zn8aNLTmf8iQPDDktikJKDxBUNUHdMbV0DP19YxoOvvUef1GR+fOnpfG7KMN3pVI5K3UoSdzRAfXxee7eKC+95nfteLePTE05kwbfP5/NnDldikGNqzxrSj5hZpZmtiiorMrPFTetEm9nUoPwqM1sRPP5iZhOjjskys2fMbK2ZrTGzjwTlg8xsnpmtD35md8cHld7lhMwM7r9KA9THUrm7lq89uZRZj/yVlCTjyf93JvdcUUTugPSwQ5M40J6Ww6PARc3K7gBudfci4ObgOcD7wDR3nwDcBsyNOuanwB/cfRwwEVgTlP8zsMDdxwALgucibZp6sgaoW9PQ6Dz2l43MuPs1Xlm9lW9dcAov3XAuHx2dE3ZoEkfaHHNw99fNbETzYqBpFCsTqAjq/iWqzmKgAMDMBgLnAf8Q1DsINN3taiZwfrD9GPBH4Mbj+AySwDRAfaRVH+7ie8+tZEX5Ls4dk8NtM09jRE6/sMOSONTRAekbgJfN7C4irY+PtlLnGuClYHskUAX8T9DVtAT4prvvBfLdfQuAu28xs7yjvamZzQZmAwwfPryDoUtvogHqiD21ddz9yrs8vmgjg/ql87Mrz+DiCUPi8iZ5Ehs6OiB9HTDH3YcBc4CHo3ea2ceIJIemFkAKMAl4wN3PAPbSge4jd5/r7sXuXpyb2/ULjEh8SuQBanfnxZVbKPmP13hs0UauOvMkFnx7Gn838UQlBumUjiaHWcCzwfbTwNSmHWY2AXgImOnu24PicqDc3d8Mnj9DJFkAbDWzIcGxQ4DKDsYkCSwRB6g3bd/Hlx59i+t/uZTB/dJ57vqzue2S07T2hXSJjiaHCmBasD0dWA9gZsOJJI0vuPuhEUJ3/xuw2cya7rk8A1gdbP+WSLIh+PlCB2OSBJcoA9QH6xv5+cIyLrjnNd56v5offHo8v/3a2RQNywo7NOlF2hxzMLOniAwY55hZOXALcC3wUzNLAWoJxgGIzFwaDNwfNGnro1Yc+jrwSzNLAzYAXwrKfwL8xsyuATYBn+mCzyUJqrcPUL+5YTvff34VZZU1fOK0E7j54vEMydS9kKTraZlQ6XVq6xq4Yu5iyrbu4fmvnt0rBqgrd9dyx8vreGZJOQXZffjhzFOZPi4/7LAkDrV3mVAlB+mVtuzaz8X3vcGAjNS4W4P6QH0D71TsZtmmnSwv38myzTv5YPs+UpKMa88byTemj+n2xeWl99Ia0pLQhmT24f6rJvP5/46sQf3wrCkxebsId2fj9n0s27yDZZsiiWD1lt3UNUS+tOUPTKdoWBafmzKcC8bnd3hReZHjpeQgvVbTAPUPXniHe2JkDerqvQdZvnknb2+OJILlm3cemnrbNy2Z04dm8uVzTuaMYVkUDcvmhMzuX0hepDVKDtKrhTlAfaC+gdUVu1kWJIKm7iGAJINT8gfwidNOYOKwLIqGZTEmrz8pWn1NYoSSg/RqPXUF9fF0DxUNy+L0gkz6p+vXT2KXBqQlIXT1APWOvQdZFnQPLd8cGTjeue/I7qGi4VnqHpKYowFpkSidGaBuT/fQRace7h46JX8AyTE4+C1yPJQcJGG0Z4C6RfdQ+S7WVOzmYEMjoO4hSRz6Xy0JpfkA9ZknD2ZZ+c5D4wStdQ996ZwR6h6ShKPkIAkleoD6q0++TUNwg77o7qGiYVlMVPeQJDglB0k4Tbf4vnf+u5w0uB9Fw7KYUJBJP3UPiRyi3wZJSCdkZvCTyyaEHYZIzNIVNyIi0oKSg4iItKDkICIiLSg5iIhIC0oOIiLSgpKDiIi0oOQgIiItKDmIiEgLcXvLbjOrAj7o4OE5wLYuDKe7xVO8irX7xFO88RQrxFe8nY31JHfPbatS3CaHzjCz0vbczzxWxFO8irX7xFO88RQrxFe8PRWrupVERKQFJQcREWkhUZPD3LADOE7xFK9i7T7xFG88xQrxFW+PxJqQYw4iInJsidpyEBGRY0iI5GBmG81spZktM7PSoGyQmc0zs/XBz+yQYnvEzCrNbFVUWauxWcTPzKzMzFaY2aQYifdfzezD4PwuM7NPRu27KYh3nZl9vIdjHWZmC81sjZm9Y2bfDMpj7vweI9ZYPbcZZvZXM1sexHtrUH6ymb0ZnNtfm1laUJ4ePC8L9o+IgVgfNbP3o85tUVAeC79nyWb2tpn9Lnje8+fV3Xv9A9gI5DQruwP452D7n4HbQ4rtPGASsKqt2IBPAi8BBpwFvBkj8f4r8J1W6o4HlgPpwMnAe0ByD8Y6BJgUbA8A3g1iirnze4xYY/XcGtA/2E4F3gzO2W+AzwXlDwLXBdvXAw8G258Dfh0DsT4KXN5K/Vj4PfsW8CTwu+B5j5/XhGg5HMVM4LFg+zHgkjCCcPfXgepmxUeLbSbwuEcsBrLMbEjPRBpxlHiPZibwK3c/4O7vA2XA1G4Lrhl33+LuS4PtPcAaYCgxeH6PEevRhH1u3d1rgqepwcOB6cAzQXnzc9t0zp8BZphZjyzQfYxYjybU3zMzKwA+BTwUPDdCOK+JkhwceMXMlpjZ7KAs3923QOQXE8gLLbqWjhbbUGBzVL1yjv0HpCd9LWiCPxLVRRcz8QbN7TOIfGuM6fPbLFaI0XMbdH0sAyqBeURaLzvdvb6VmA7FG+zfBQwOK1Z3bzq3PwrO7T1mlt481kBPn9t7gX8CGoPngwnhvCZKcjjb3ScBnwC+ambnhR1QB7X2jSAWpps9AIwCioAtwN1BeUzEa2b9gf8FbnD33ceq2kpZj8bbSqwxe27dvcHdi4ACIq2WwmPEFGq8zWM1s9OAm4BxwBRgEHBjUD20WM3s00Cluy+JLj5GPN0Wa0IkB3evCH5WAs8R+Y+8tampGPysDC/CFo4WWzkwLKpeAVDRw7G14O5bg1++RuC/Ody9EXq8ZpZK5I/tL9392aA4Js9va7HG8rlt4u47gT8S6Z/PMrOUVmI6FG+wP5P2d092mahYLwq68tzdDwD/Q2yc27OBvzOzjcCviHQn3UsI57XXJwcz62dmA5q2gQuBVcBvgVlBtVnAC+FE2KqjxfZb4IvBbIqzgF1N3SNhatYfeymR8wuReD8XzKg4GRgD/LUH4zLgYWCNu/9H1K6YO79HizWGz22umWUF232AEiLjJAuBy4Nqzc9t0zm/HHjVg1HUkGJdG/UFwYj04Uef21D+H7j7Te5e4O4jiAwwv+ruVxHGee3KEfZYfAAjiczqWA68A3w/KB8MLADWBz8HhRTfU0S6C+qIfAu45mixEWlC/pxI3+5KoDhG4v1FEM+K4D/rkKj63w/iXQd8oodjPYdIE3sFsCx4fDIWz+8xYo3VczsBeDuIaxVwc1A+kkiSKgOeBtKD8ozgeVmwf2QMxPpqcG5XAU9weEZT6L9nQRznc3i2Uo+fV10hLSIiLfT6biURETl+Sg4iItKCkoOIiLSg5CAiIi0oOYiISAtKDiIi0oKSg4iItKDkICIiLfx/VKvcg4sC7eYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Find the best parameter value\n",
    "\n",
    "Given the results, which value for `n_estimators` seems best for the random forest model?  Use your answer to set the value of `n_estimators_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_best = min(results, key=results.get)\n",
    "n_estimators_best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
